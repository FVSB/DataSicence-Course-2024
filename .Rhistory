params=hiperparametros,
nrounds = 100,
watchlist=watchlist,
early_stopping_rounds = 10)
predictTest.xgb <- as.data.frame(predict(xgb.model,one_hot_encoding.test.DMatrix))
predictTestAux.xgb <- prediction(predictTest.xgb[,1],test$default)
auc_ROC<-performance(predictTestAux.xgb, "auc")
auc_ROC@y.values[[1]]
watchlist <- list(train=one_hot_encoding.training.DMatrix,
valid=one_hot_encoding.validation.DMatrix)
hiperparametros<-list(subsample = 0.64, # Porcentaje de observaciones de cada muestra
max_depth = 12, # Profundidad de los ?rboles
eta = 0.1) # Tasa de aprendizaje)
xgb.model <- xgb.train(one_hot_encoding.training.DMatrix,
params=hiperparametros,
nrounds = 100,
watchlist=watchlist,
early_stopping_rounds = 10)
predictTest.xgb <- as.data.frame(predict(xgb.model,one_hot_encoding.test.DMatrix))
predictTestAux.xgb <- prediction(predictTest.xgb[,1],test$default)
auc_ROC<-performance(predictTestAux.xgb, "auc")
auc_ROC@y.values[[1]]
set.seed(12345)
watchlist <- list(train=one_hot_encoding.training.DMatrix,
valid=one_hot_encoding.validation.DMatrix)
hiperparametros<-list(subsample = 0.64, # Porcentaje de observaciones de cada muestra
max_depth = 12, # Profundidad de los ?rboles
eta = 0.3) # Tasa de aprendizaje)
xgb.model <- xgb.train(one_hot_encoding.training.DMatrix,
params=hiperparametros,
nrounds = 100,
watchlist=watchlist,
early_stopping_rounds = 10)
predictTest.xgb <- as.data.frame(predict(xgb.model,one_hot_encoding.test.DMatrix))
predictTestAux.xgb <- prediction(predictTest.xgb[,1],test$default)
auc_ROC<-performance(predictTestAux.xgb, "auc")
auc_ROC@y.values[[1]]
watchlist <- list(train=one_hot_encoding.training.DMatrix,
valid=one_hot_encoding.validation.DMatrix)
hiperparametros<-list(subsample = 0.64, # Porcentaje de observaciones de cada muestra
max_depth = 12, # Profundidad de los ?rboles
eta = 0.05) # Tasa de aprendizaje)
xgb.model <- xgb.train(one_hot_encoding.training.DMatrix,
params=hiperparametros,
nrounds = 100,
watchlist=watchlist,
early_stopping_rounds = 10)
predictTest.xgb <- as.data.frame(predict(xgb.model,one_hot_encoding.test.DMatrix))
predictTestAux.xgb <- prediction(predictTest.xgb[,1],test$default)
auc_ROC<-performance(predictTestAux.xgb, "auc")
auc_ROC@y.values[[1]]
# 0.8038979 > 0.5498448 (Regresion continua arrojando mejores resultados)
hiperparametros<-list(subsample = 0.75, # Porcentaje de observaciones de cada muestra
max_depth = 12, # Profundidad de los ?rboles
eta = 0.05) # Tasa de aprendizaje)
xgb.model <- xgb.train(one_hot_encoding.training.DMatrix,
params=hiperparametros,
nrounds = 100,
watchlist=watchlist,
early_stopping_rounds = 10)
predictTest.xgb <- as.data.frame(predict(xgb.model,one_hot_encoding.test.DMatrix))
predictTestAux.xgb <- prediction(predictTest.xgb[,1],test$default)
auc_ROC<-performance(predictTestAux.xgb, "auc")
auc_ROC@y.values[[1]]
rm(list=ls())
setwd("C:/Users/53527/Desktop/Curso_CD_UCM/morosidad/")
train <- read.csv("datamart_morosidad_training.csv", fileEncoding="utf-8",stringsAsFactors = TRUE)
test <- read.csv("datamart_morosidad_test.csv", fileEncoding="utf-8",stringsAsFactors = TRUE)
rm(list=ls())
setwd("C:/Users/paco2/Documents/GitHub/untitled/")
train_table <- read.csv("datamart_morosidad_training.csv", fileEncoding="utf-8", stringsAsFactors = TRUE)
test_table <- read.csv("datamart_morosidad_test.csv", fileEncoding="utf-8", stringsAsFactors = TRUE)
summary(train_table)
install.packages("moments")
library(moments)
descriptivoManual <- function(explanatory_Table){
vars_names <- names(explanatory_Table)
for (i in vars_names){
print(paste0("Variable:  ",i))
print(paste0("Tipo de variable:  ", class(explanatory_Table[, i])))
if (class(explanatory_Table[, i])=="factor"){
#Calculando la moda:
valores <- unique(explanatory_Table[, i])
moda <- valores[which.max(tabulate(match(tablaExplicativas[,i], valores)))]
print(paste0("Moda:  ", moda))
print(paste0("Nº de niveles:  ", length(valores)))
print(paste0("% de missings:  ", 100*(sum(is.na(explanatory_Table[, i]))/length(explanatory_Table[, i])), "%"))
} else{
print(paste0("Mínimo:  ", min(explanatory_Table[, i], na.rm = T)))
print(paste0("Máximo:  ", max(explanatory_Table[, i], na.rm = T)))
print(paste0("Media:  ", mean(explanatory_Table[, i], na.rm = T)))
print(paste0("Mediana:  ", median(explanatory_Table[, i], na.rm = T)))
print(paste0("Desviación típica:  ", sd(explanatory_Table[, i], na.rm = T)))
print(paste0("Asimetría:  ", skewness(explanatory_Table[, i], na.rm = T)))
print(paste0("Curtosis:  ", kurtosis(explanatory_Table[, i], na.rm = T)))
print(paste0("% de missings:  ", 100*(sum(is.na(explanatory_Table[, i]))/length(explanatory_Table[, i])), "%"))
}
print("*******************************ge**************")
}
}
descriptivoManual(train_table[, c("Age", "Avgexp", "Income", "Inc_per", "Cur_add", "Active")])
class(train_table)
hist(train_table$Avgexp, col="purple", border = F,
main = "Histograma de Avgexp del cliente",
xlab = "Valor", ylab = "Frecuencia")
hist(train_table$Age, col="purple", border = F,
main = "Age",
xlab = "Valor", ylab = "Frecuencia")
hist(train_table$Income, col="purple", border = F,
main = "Income",
xlab = "Valor", ylab = "Frecuencia")
hist(train_table$Inc_per, col="purple", border = F,
main = "Inc_per",
xlab = "Valor", ylab = "Frecuencia")
hist(train_table$Cur_add, col="purple", border = F,
main = "Curr_add",
xlab = "Valor", ylab = "Frecuencia")
hist(train_table$Active, col="purple", border = F,
main = "Active",
xlab = "Valor", ylab = "Frecuencia")
boxplot(train_table$Avgexp, col = "purple", main = "Boxplot de Avgexp")
boxplot(train_table$Inc_per, col = "purple", main = "Boxplot de Inc_per")
correlationMatrix<-cor(train_table[, c("Avgexp", "Age", "Income", "Inc_per")], method = c("pearson"))
graphics.off()
install.packages("corrplot")
library(corrplot)
install.packages("dplyr")
library(dplyr)
install.packages("ggcorrplot")
library(ggcorrplot)
correlationMatrix<-cor(train_table[c("Avgexp", "Age", "Income", "Inc_per", "Active", "Cur_add", "Ownrent", "Selfempl", "Exp_Inc", "Depndt", "Major")], method = c("pearson"))
corrplot(correlationMatrix, method="number", type="upper", tl.cex=0.5)
train_table$default <- as.factor(train_table$default)
train_table$Depndt <- as.factor(train_table$Depndt)
train_table$Depndt<-as.factor(train_table$Depndt)
train_table$default<-as.factor(train_table$default)
tablaFrecuencia<-table(train_table$default, train_table$Active)
barplot(tablaFrecuencia, col = c('springgreen1','purple'), border = F)
tablaFrecuencia<-table(train_table$default, train_table$Depndt)
barplot(tablaFrecuencia, col = c('springgreen1','purple'), border = F)
table(train_table$default)
set.seed(7784)
undersampling <- function(data, objective_var, ones_proportion_wish){
`1s_counts` <- nrow(subset(data, objective_var==1))
`0s_counts` <- round((`1s_counts`/ones_proportion_wish)-`1s_counts`)
`0sstable` <- subset(data, objective_var==0)
zeros <- sample(nrow(`0sstable`), `0s_counts`, replace = FALSE)
return(rbind(data[variableObjetivo==1,], `0sstable`[ceros,]))
}
undersampling_0.5 <- undersampling(train_table, train_table$default, 1/2)
table(undersampling_0.5$default)
undersampling_0.33 <- undersampling(train_table, train_table$default, 1/3)
table(undersampling_0.33$default)
ones_table <- subset(train_table, train_table$default==1)
zeros_table <- subset(train_table, train_table$default==0)
ones_clones <- sample(nrow(ones_table), nrow(zeros_table), replace=TRUE)
ones_table <- ones_table[ones_clones,]
sobremuestreo_0_5 <- rbind(zeros_table, ones_table)
table(sobremuestreo_0_5$default)
percentile_Avgexp <- quantile(train_table$Avgexp, c(0.90, 0.95, 0.97, 0.99, 1), na.rm = T)
percentilesInc_per <- quantile(train_table$Inc_per, c(0.90, 0.95,0.97, 0.99, 1), na.rm = T)
without_outliders_trainTrable <- train_table[train_table$Avgexp<=percentile_Avgexp[[3]] & train_table$Inc_per<=percentilesInc_per[[3]],]
dim(train_table)
dim(without_outliders_trainTrable)
(nrow(train_table)-nrow(without_outliders_trainTrable))
hist(train_table$Avgexp, col="purple", border = F,
main = "Histograma de Avgexp del cliente",
xlab = "Valor", ylab = "Frecuencia")
hist(without_outliders_trainTrable$Avgexp, col="purple", border = F,
main = "Histograma de Avgexp del cliente",
xlab = "Valor", ylab = "Frecuencia")
hist(train_table$Inc_per, col="purple", border = F,
main = "Histograma de Inc_per del cliente",
xlab = "Valor", ylab = "Frecuencia")
hist(without_outliders_trainTrable$Inc_per, col="purple", border = F,
main = "Histograma de Inc_per del cliente",
xlab = "Valor", ylab = "Frecuencia")
model_logistReg_Interc <- glm(default ~ 1, data=without_outliders_trainTrable, family=binomial(link="logit") )
# Modelo m?s complejo a generar: con todas las variables
# No vamos a tener en cuenta Exp_Inc x su correlacion con Avgexp
model_logist_All <- glm(default ~ Avgexp+Age+Income+Inc_per+Active+Cur_add+Ownrent+Selfempl+Depndt+Major, data=without_outliders_trainTrable, family=binomial(link="logit") )
modelo.regresionLogistica.stepwise <- step(model_logistReg_Interc, scope=list(lower=model_logistReg_Interc,
upper=model_logist_All), direction="both")
modelo.regresionLogistica.stepwise
# install.packages("lmtest")
library(lmtest)
coeftest(modelo.regresionLogistica.stepwise)
predictTest.logisticaStepwise <- predict(modelo.regresionLogistica.stepwise,
newdata=test_table,
type="response")
install.packages("gplots")
library(gplots)
install.packages("ROCR")
library(ROCR)
predict_TestAux_logisticStepwise <- prediction(predictTest.logisticaStepwise,
test_table$default,
label.ordering = NULL)
roc_CurveTest_logisticStepwise <- performance(predict_TestAux_logisticStepwise, "tpr", "fpr")
auc_ROC<-performance(predict_TestAux_logisticStepwise, "auc")
auc_ROC@y.values[[1]]
plot(precision, main="Gr?fico de precisi?n", colorize=T)
print(prior)
# L?nea base
abline(a=prior,b=0,col="black")
coverage<-performance(predict_TestAux_logisticStepwise, "rec", "rpp")
plot(coverage, main="Gráfico de cobertura", colorize=T)
# L?nea base
abline(a=0,b=1,col="black")
lift<-performance(predict_TestAux_logisticStepwise, "lift", "rpp")
plot(lift, main="Gr?fico lift", colorize=T)
# L?nea base
abline(a=1,b=0,col="black")
install.packages("partykit")
library(partykit)
`dependencies tree.fit` <- ctree(default~Avgexp+Age+Income+Inc_per+Active+Cur_add+Ownrent+Selfempl+Depndt+Major,
data=train_table, control=ctree_control(alpha=0.01, maxdepth=3, minbucket = 30))
graphics.off()
plot(`dependencies tree.fit`)
install.packages("rpart")
library(rpart)
Gini_tree.fit <- rpart(default~Avgexp+Age+Income+Inc_per+Active+Cur_add+Ownrent+Selfempl+Depndt+Major,
data=train_table, method="class",
parms = list(split = "gini"), control= rpart.control(minbucket = 30, maxdepth = 3, cp=0.05))
Gini_tree.fit
Gini_tree.fit <- rpart(default~Avgexp+Age+Income+Inc_per+Active+Cur_add+Ownrent+Selfempl+Depndt+Major,
data=train_table, method="class",
parms = list(split = "gini"), control= rpart.control(minbucket = 30, maxdepth = 3, cp=0.002))
Gini_tree.fit
Gini_tree.fit.without_prune <- rpart(default~Avgexp+Age+Income+Inc_per+Active+Cur_add+Ownrent+Selfempl+Depndt+Major,
data=train_table, method="class",
parms = list(split = "gini"), control= rpart.control(minbucket = 30, maxdepth = 3, cp=-1))
Gini_tree.fit.without_prune
install.packages("rattle")
library(rattle)
install.packages("rpart.plot")
library(rpart.plot)
install.packages("RColorBrewer")
install.packages("ggcorrplot")
library(RColorBrewer)
install.packages("ROCR")
fancyRpartPlot(Gini_tree.fit.without_prune, caption=NULL, palettes=c("Purples"))
plotcp(Gini_tree.fit.without_prune)
printcp(Gini_tree.fit.without_prune)
##################################################
##################################################
# 5. Valoraci?n: ROC, Cobertura, Precisi?n, LIFT #
##################################################
##################################################
test_table$Depndt <- as.factor(test_table$Depndt)
predictTest.tree <-predict(Gini_tree.fit.without_prune, type='prob', test_table)
predictTestAux.tree <- prediction(predictTest.tree[, 2], test_table$default)
RocTest.tree <- performance(predictTestAux.tree, "tpr", "fpr")
plot(RocTest.tree, main="Curva ROC", colorize=TRUE)
# L?nea base
abline(a=0,b=1,col="black")
auc_ROC<-performance(predictTestAux.tree, "auc")
auc_ROC@y.values[[1]]
precision<-performance(predictTestAux.tree, "prec", "rpp")
plot(precision, main="Gr?fico de precisi?n", colorize=T)
prior=sum(train_table$default==1)/length(train_table$default)
print(prior)
# L?nea base
abline(a=prior,b=0,col="black")
coverage<-performance(predictTestAux.tree, "rec", "rpp")
plot(coverage, main="Gr?fico de cobertura", colorize=T)
# L?nea base
abline(a=0,b=1,col="black")
lift<-performance(predictTestAux.tree, "lift", "rpp")
plot(lift, main="Gr?fico lift", colorize=T)
# L?nea base
abline(a=1,b=0,col="black")
lossmatrix <- matrix(c(0,360,10,0), byrow = TRUE, nrow = 2)
arbolGini_Cost.fit <- rpart(default~Avgexp+Age+Income+Inc_per+Active+Cur_add+Ownrent+Selfempl+Depndt+Major,
data=train_table, method="class",
parms = list(prior = c(.025,.975),split = "gini", loss=lossmatrix),
control= rpart.control(minbucket = 30, maxdepth = 3, cp=-1))
graphics.off()
fancyRpartPlot(arbolGini_Cost.fit,caption=NULL,palettes=c("Purples"))
predictTest.tree <-predict(arbolGini_Cost.fit, type='prob', test_table)
predictTestAux.tree <- prediction(predictTest.tree[, 2], test_table$default)
RocTest.tree <- performance(predictTestAux.tree, "tpr", "fpr")
plot(RocTest.tree, main="Curva ROC", colorize=TRUE)
# L?nea base
abline(a=0,b=1,col="black")
auc_ROC<-performance(predictTestAux.tree, "auc")
auc_ROC@y.values[[1]]
precision<-performance(predictTestAux.tree, "prec", "rpp")
plot(precision, main="Gr?fico de precisi?n", colorize=T)
prior=sum(train_table$default==1)/length(train_table$default)
print(prior)
# L?nea base
abline(a=prior,b=0,col="black")
coverage<-performance(predictTestAux.tree, "rec", "rpp")
plot(coverage, main="Gr?fico de cobertura", colorize=T)
# L?nea base
abline(a=0,b=1,col="black")
lift<-performance(predictTestAux.tree, "lift", "rpp")
plot(lift, main="Gr?fico lift", colorize=T)
# L?nea base
abline(a=1,b=0,col="black")
install.packages('randomForest')
rm(list=ls())
setwd("C:/Users/paco2/Documents/GitHub/untitled/")
train_table <- read.csv("datamart_morosidad_training.csv", fileEncoding="utf-8", stringsAsFactors = TRUE)
test_table <- read.csv("datamart_morosidad_test.csv", fileEncoding="utf-8", stringsAsFactors = TRUE)
rm(list=ls())
# Obtiene el directorio de trabajo actual
directorio_actual <- getwd()
# Obtiene el directorio de trabajo actual
directorio_actual <- getwd()
print(directorio_actual)
# Obtiene el directorio de trabajo actual
directorio_actual <- getwd()
setwd(directorio_actual)
train_table <- read.csv("datamart_morosidad_training.csv", fileEncoding="utf-8", stringsAsFactors = TRUE)
test_table <- read.csv("datamart_morosidad_test.csv", fileEncoding="utf-8", stringsAsFactors = TRUE)
setwd(directorio_actual)
train_table <- read.csv("datamart_morosidad_training.csv", fileEncoding="utf-8", stringsAsFactors = TRUE)
print(train_table)
test_table <- read.csv("datamart_morosidad_test.csv", fileEncoding="utf-8", stringsAsFactors = TRUE)
print(test_table)
descriptivoManual <- function(explanatory_Table){
vars_names <- names(explanatory_Table)
for (i in vars_names){
print(paste0("Variable:  ",i))
print(paste0("Tipo de variable:  ", class(explanatory_Table[, i])))
if (class(explanatory_Table[, i])=="factor"){
#Calculando la moda:
valores <- unique(explanatory_Table[, i])
moda <- valores[which.max(tabulate(match(tablaExplicativas[,i], valores)))]
print(paste0("Moda:  ", moda))
print(paste0("Nº de niveles:  ", length(valores)))
print(paste0("% de missings:  ", 100*(sum(is.na(explanatory_Table[, i]))/length(explanatory_Table[, i])), "%"))
} else{
print(paste0("Mínimo:  ", min(explanatory_Table[, i], na.rm = T)))
print(paste0("Máximo:  ", max(explanatory_Table[, i], na.rm = T)))
print(paste0("Media:  ", mean(explanatory_Table[, i], na.rm = T)))
print(paste0("Mediana:  ", median(explanatory_Table[, i], na.rm = T)))
print(paste0("Desviación típica:  ", sd(explanatory_Table[, i], na.rm = T)))
print(paste0("Asimetría:  ", skewness(explanatory_Table[, i], na.rm = T)))
print(paste0("Curtosis:  ", kurtosis(explanatory_Table[, i], na.rm = T)))
print(paste0("% de missings:  ", 100*(sum(is.na(explanatory_Table[, i]))/length(explanatory_Table[, i])), "%"))
}
print("*******************************ge**************")
}
}
descriptivoManual(train_table[, c("Age", "Avgexp", "Income", "Inc_per", "Cur_add", "Active")])
descriptivoManual <- function(explanatory_Table){
# Obtiene los nombres de las variables de la tabla de datos
vars_names <- names(explanatory_Table)
# Itera sobre cada nombre de variable
for (i in vars_names){
# Imprime el nombre de la variable
print(paste0("Variable: ",i))
# Imprime el tipo de variable (factor, numérico, etc.)
print(paste0("Tipo de variable: ", class(explanatory_Table[, i])))
# Verifica si la variable es de tipo factor
if (class(explanatory_Table[, i])=="factor"){
# Calcula la moda de la variable factor
valores <- unique(explanatory_Table[, i])
moda <- valores[which.max(tabulate(match(explanatory_Table[,i], valores)))]
print(paste0("Moda: ", moda))
# Imprime el número de niveles de la variable factor
print(paste0("Nº de niveles: ", length(valores)))
# Calcula y muestra el porcentaje de valores faltantes (NA)
print(paste0("% de missings: ", 100*(sum(is.na(explanatory_Table[, i]))/length(explanatory_Table[, i])), "%"))
} else{
# Si la variable no es factor, calcula y muestra estadísticas descriptivas numéricas
print(paste0("Mínimo: ", min(explanatory_Table[, i], na.rm = T)))
print(paste0("Máximo: ", max(explanatory_Table[, i], na.rm = T)))
print(paste0("Media: ", mean(explanatory_Table[, i], na.rm = T)))
print(paste0("Mediana: ", median(explanatory_Table[, i], na.rm = T)))
print(paste0("Desviación típica: ", sd(explanatory_Table[, i], na.rm = T)))
print(paste0("Asimetría: ", skewness(explanatory_Table[, i], na.rm = T)))
print(paste0("Curtosis: ", kurtosis(explanatory_Table[, i], na.rm = T)))
# Calcula y muestra el porcentaje de valores faltantes (NA)
print(paste0("% de missings: ", 100*(sum(is.na(explanatory_Table[, i]))/length(explanatory_Table[, i])), "%"))
}
# Imprime una línea divisoria para separar la salida de cada variable
print("*********************************************")
}
}
descriptivoManual(train_table[, c("Age", "Avgexp", "Income", "Inc_per", "Cur_add", "Active")])
class(train_table)
hist(train_table$Avgexp, col="purple", border = F,
main = "Histograma de Avgexp del cliente",
xlab = "Valor", ylab = "Frecuencia")
hist(train_table$Age, col="purple", border = F,
main = "Age",
xlab = "Valor", ylab = "Frecuencia")
hist(train_table$Income, col="purple", border = F,
main = "Income",
xlab = "Valor", ylab = "Frecuencia")
hist(train_table$Inc_per, col="purple", border = F,
main = "Inc_per",
xlab = "Valor", ylab = "Frecuencia")
hist(train_table$Cur_add, col="purple", border = F,
main = "Curr_add",
xlab = "Valor", ylab = "Frecuencia")
hist(train_table$Active, col="purple", border = F,
main = "Active",
xlab = "Valor", ylab = "Frecuencia")
boxplot(train_table$Avgexp, col = "purple", main = "Boxplot de Avgexp")
boxplot(train_table$Inc_per, col = "purple", main = "Boxplot de Inc_per")
correlationMatrix<-cor(train_table[, c("Avgexp", "Age", "Income", "Inc_per")], method = c("pearson"))
graphics.off()
install.packages("corrplot")
library(corrplot)
install.packages("dplyr")
library(dplyr)
install.packages("ggcorrplot")
library(ggcorrplot)
correlationMatrix<-cor(train_table[c("Avgexp", "Age", "Income", "Inc_per", "Active", "Cur_add", "Ownrent", "Selfempl", "Exp_Inc", "Depndt", "Major")], method = c("pearson"))
corrplot(correlationMatrix, method="number", type="upper", tl.cex=0.5)
corrplot(correlationMatrix, method="number", type="upper", tl.cex=0.5)
ntcorrplot(matrizCorrelacion, method="number", type="upper",tl.cex=0.5)
train_table$default<-as.factor(train_table$default)
tablaFrecuencia<-table(train_table$default, train_table$Active)
barplot(tablaFrecuencia, col = c('springgreen1','purple'), border = F)
tablaFrecuencia<-table(train_table$default, train_table$Depndt)
barplot(tablaFrecuencia, col = c('springgreen1','purple'), border = F)
table(train_table$default)
set.seed(7784)
undersampling <- function(data, objective_var, ones_proportion_wish){
`1s_counts` <- nrow(subset(data, objective_var==1))
`0s_counts` <- round((`1s_counts`/ones_proportion_wish)-`1s_counts`)
`0sstable` <- subset(data, objective_var==0)
zeros <- sample(nrow(`0sstable`), `0s_counts`, replace = FALSE)
return(rbind(data[variableObjetivo==1,], `0sstable`[ceros,]))
}
undersampling_0.5 <- undersampling(train_table, train_table$default, 1/2)
table(train_table$default)
set.seed(12345)
undersampling <- function(data, objective_var, ones_proportion_wish){
`1s_counts` <- nrow(subset(data, objective_var==1))
`0s_counts` <- round((`1s_counts`/ones_proportion_wish)-`1s_counts`)
`0sstable` <- subset(data, objective_var==0)
zeros <- sample(nrow(`0sstable`), `0s_counts`, replace = FALSE)
return(rbind(data[variableObjetivo==1,], `0sstable`[ceros,]))
}
undersampling_0.5 <- undersampling(train_table, train_table$default, 1/2)
table(undersampling_0.5$default)
undersampling_0.33 <- undersampling(train_table, train_table$default, 1/3)
table(undersampling_0.33$default)
ones_table <- subset(train_table, train_table$default==1)
zeros_table <- subset(train_table, train_table$default==0)
ones_clones <- sample(nrow(ones_table), nrow(zeros_table), replace=TRUE)
ones_table <- ones_table[ones_clones,]
sobremuestreo_0_5 <- rbind(zeros_table, ones_table)
table(sobremuestreo_0_5$default)
percentile_Avgexp <- quantile(train_table$Avgexp, c(0.90, 0.95, 0.97, 0.99, 1), na.rm = T)
percentilesInc_per <- quantile(train_table$Inc_per, c(0.90, 0.95,0.97, 0.99, 1), na.rm = T)
without_outliders_trainTrable <- train_table[train_table$Avgexp<=percentile_Avgexp[[3]] & train_table$Inc_per<=percentilesInc_per[[3]],]
dim(train_table)
percentile_Avgexp <- quantile(train_table$Avgexp, c(0.90, 0.95, 0.97, 0.99, 1), na.rm = T)
print(percentile_Avgexp)
percentilesInc_per <- quantile(train_table$Inc_per, c(0.90, 0.95,0.97, 0.99, 1), na.rm = T)
percentilesInc_per <- quantile(train_table$Inc_per, c(0.90, 0.95,0.97, 0.99, 1), na.rm = T)
print/percentilesInc_per)
percentilesInc_per <- quantile(train_table$Inc_per, c(0.90, 0.95,0.97, 0.99, 1), na.rm = T)
print(percentilesInc_per)
without_outliders_trainTrable <- train_table[train_table$Avgexp<=percentile_Avgexp[[3]] & train_table$Inc_per<=percentilesInc_per[[3]],]
dim(train_table)
dim(without_outliders_trainTrable)
(nrow(train_table)-nrow(without_outliders_trainTrable))
hist(train_table$Avgexp, col="purple", border = F,
main = "Histograma de Avgexp del cliente",
xlab = "Valor", ylab = "Frecuencia")
hist(without_outliders_trainTrable$Avgexp, col="purple", border = F,
main = "Histograma de Avgexp del cliente",
xlab = "Valor", ylab = "Frecuencia")
hist(train_table$Inc_per, col="purple", border = F,
main = "Histograma de Inc_per del cliente",
xlab = "Valor", ylab = "Frecuencia")
hist(without_outliders_trainTrable$Inc_per, col="purple", border = F,
main = "Histograma de Inc_per del cliente",
xlab = "Valor", ylab = "Frecuencia")
model_logistReg_Interc <- glm(default ~ 1, data=without_outliders_trainTrable, family=binomial(link="logit") )
# Modelo m?s complejo a generar: con todas las variables
# No vamos a tener en cuenta Exp_Inc x su correlacion con Avgexp
model_logist_All <- glm(default ~ Avgexp+Age+Income+Inc_per+Active+Cur_add+Ownrent+Selfempl+Depndt+Major, data=without_outliders_trainTrable, family=binomial(link="logit") )
modelo.regresionLogistica.stepwise <- step(model_logistReg_Interc, scope=list(lower=model_logistReg_Interc,
upper=model_logist_All), direction="both")
modelo.regresionLogistica.stepwise
# install.packages("lmtest")
library(lmtest)
coeftest(modelo.regresionLogistica.stepwise)
predictTest.logisticaStepwise <- predict(modelo.regresionLogistica.stepwise,
newdata=test_table,
type="response")
install.packages("gplots")
library(gplots)
install.packages("ROCR")
library(ROCR)
predict_TestAux_logisticStepwise <- prediction(predictTest.logisticaStepwise,
test_table$default,
label.ordering = NULL)
roc_CurveTest_logisticStepwise <- performance(predict_TestAux_logisticStepwise, "tpr", "fpr")
plot(roc_CurveTest_logisticStepwise, main="Curva ROC", colorize=TRUE)
# L?nea base
abline(a=0,b=1,col="black")
auc_ROC<-performance(predict_TestAux_logisticStepwise, "auc")
auc_ROC@y.values[[1]]
precision<-performance(predict_TestAux_logisticStepwise, "prec", "rpp")
plot(precision, main="Gr?fico de precisi?n", colorize=T)
prior=sum(train_table$default==1)/length(train_table$default)
print(prior)
# L?nea base
abline(a=prior,b=0,col="black")
coverage<-performance(predict_TestAux_logisticStepwise, "rec", "rpp")
install.packages("ROCR")
install.packages("ROCR")
